install.packages("rpart")
install.packages("rnet")
install.packages("nnet")
install.packages("neuralnet")
install.packages("DMwR")
install.packages("e1064")
install.packages("E1064")
install.packages("E1071")
install.packages("e1071")
install.packages("arul")
install.packages("arule")
install.packages("arules")
install.packages("DMwR2")
library()
install.packages("neutralnet")
install.packages("neuralnet")
library()
install.packages("https://CRAN.R-project.org/package=DMwR")
library(rpart)
# TP classification
data = iris
library(rpart)
rpart(species~ , iris) -> Ad
rpart(species~ . , iris) -> Ad
plot(Ad)
rpart(species ~. , iris) -> Ad
# TP classification
library(rpart)
rpart(species ~. , iris) -> Ad
rpart(species , iris) -> Ad
rpart(Species , iris) -> Ad
plot(Ad)
text(Ad)
# TP classification
library(rpart);
rpart(Species , iris) -> Ad;
rpart(Species~. ,iris) -> Ad;
plot(Ad);
text(Ad);
pred = predict(Ad, iris[,-5])
View(pred)
View(data)
View(pred)
View(Ad)
View(Ad)
View(data)
View(Ad)
View(data)
data.frame(iris[,5],pred)
help("predict")
pred = predict(Ad, iris[,-5] , type = c("class")) # permet de supprimer la derniere colonne et le predire par la suite.
data.frame(iris[,5],pred) # mettre la derniere colonne de l'iris supprimee avec les probabilites trouves afin de confirmer la prediction
help("sample")
nt = sample(1:nrom(iris), 0.7*nrow(iris))
nt = sample(1:nrow(iris), 0.7*nrow(iris))
train = iris[nt ,]
View(train)
test = iris[-nt, ] # on affecte a test tout le dataset iris  sauf les donnees extraites pour l'entrenement du model
View(test)
View(data)
Adt <- rpart(Species~. ,train)
plot(Adt)
text(Adt)
View(Ad)
View(Ad)
View(Adt)
View(Ad)
View(Adt)
View(Ad)
poltcp(Adt)
plotcp(Adt)
plotcp(Ad)
plotcp(Ad)
# Matrice de confusion
table(test[,5],pred)
install.packages(gmodels)
install.packages("gmodels")
text(Adt)
pred1 = predict(Ad, test[,-5] , type = c("class"))
# Matrice de confusion
table(test[,5],pred1)
# Rappel et precision
library(DMwR)
install.packages("DMwR")
KNN(Species~.,train,test)
kNN(Species~.,train,test)
install.packages("DMwR2")
library(DMwR)
install.packages("shiny")
update R
upgrade R.version
R.version
install.packages("installr")
library(installr)
updateR()
updater()
library(installr)
updater()
updaterR()
updateR()
install.packages("installr")
library(installr)
updateR()
install.packages("installr")
install.packages("installr")
library(installr)
updateR()
install.packages("installr")
library(installr)
updateR()
updateR()
options(repos=c(cran="http://cran.rstudio.com"))
install.packages("shiny")
library(shiny);
install.packages("DMwR")
options(repos=c(cran="http://cran.rstudio.com"))
install.packages("DMwR")
options(repos=c(cran="http://cran.rstudio.com"))
install.packages("DMwR2")
library(DMwR)
options(repos=c(cran="http://cran.rstudio.com"))
install.packages("DMwR2")
install.packages("DMwR")
library(shiny)
library(DMwR)
install.packages("DMwR2")
install.packages()
install.packages("cli")
install.packages("stringi")
install_github("Luis Torgo/DMwR")
install_github.packages("Luis Torgo/DMwR")
install.packages("https://github.com/cran/DMwR")
options(repos=c(cran="http://cran.rstudio.com"))
install.packages("DMwR")
install.packages("devtools")
install.packages("DMwR")
install.packages("RMySQL")
install.packages(c("bit", "vctrs"))
install.packages("RMySQL")
install.packages("DMwR")
install.packages("RMySQL")
install.packages("RMySQL")
install.packages("DMwR")
install.packages("DMwR")
remotes::install_version("DMwR", version="0.4.1")
library(devtools)
install.packages("devtools")
install.packages("DMwR")
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("crx.data.txt", header =F , dec = '.',na.strings = c('?'),sep =',')
rownames(cr) # acces a la liste des lignes
colnames(cr) # acces a la liste des colonnes
dim(cr) # connaitre les dimenssion
colnames(cr) = paste("A",1:16 , sep="")
summary(cr) # avoir la description du dataset( min ,1st quartile, median , mean ,3rd ,max, length , class , mode )
cr$A10
# histogramme
hist(cr$A11 , prob = T)
plot(cr$A13,col="blue")
barplot(cr$A11)
par(mfrow =c(1, 2))
clear
cls
clc
clean
cr <-read.table("titanic.csv", header =F , dec = '.',na.strings = c('?'),sep =',')
cr <-read.table("titanic.csv", header =F , dec = '.',na.strings = c('?'),sep =',')
data <- read_excel("/home/sudo-moha/Documents/Data science/Data Mining/Exercices et TPs/TP_final_datamining/dataset.xlsx")
library(readxl)
data <- read_excel("/home/sudo-moha/Documents/Data science/Data Mining/Exercices et TPs/TP_final_datamining/dataset.xlsx")
library(readxl)
data <- read_excel("dataset.xlsx")
library(readxl)
data <- read_excel("dataset.xlsx",sheet = 1)
View(Ad)
View(Ad)
View(Adt)
View(Adt)
View(data)
View(data)
View(data)
View(test)
View(test)
View(train)
View(train)
View(Ad)
View(Ad)
library(readxl)
data <- read_excel("dataset.xlsx",sheet = 1)
data <- read_excel("dataset.xlsx",sheet = 1)
library(readxl)
data <- read_excel("dataset.xlsx",sheet = 1)
data <- read.table("dataset.csv")
library(readr)
dataset <- read_csv("Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining/dataset.csv")
View(dataset)
data <- read.table("dataset.csv")
data <- dataset
data
dim(dataset)
summary(dataset)
data = dataset[-1,]
summary(dataset)
summary(data)
data[1,]
View(data)
View(data)
data = dataset[,-1]
data[1,]
data
View(data)
View(data)
View(data)
View(data)
data <- read.csv2("dataset.csv", header = T)
data
dim(dataset)
data = dataset[,-1]
data
data = dataset[,-1]
data
View(data)
View(data)
data = dataset[,-1]
data
summary(data)
data = as.nemeric(dataset[,-1])
source('utils.r')
# Rénommons PAY_0 en PAY_1,comme ça on ne quitte plus de PAY_0 subitement à PAY_2
df[1,][df[1,]=='PAY_0'] = 'PAY_1'
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
library(dplyr)#fonction pour normaliser les colonnes numériques
source('main.r')
main()
setwd(home/sudo-moha/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining)
setwd("home/sudo-moha/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining")
setwd("~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining")
main <- function() {
#stockons le dataset dans la variable df
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#D'après la commande suivante il n'y a pas de valeurs manquantes
#print(paste('Number of missing values =',sum(is.na(df))))
#pretaitemente
df = pretraitement(df)
#summary(df)
df
}
pretraitement <- function (df){
library(dplyr)#fonction pour normaliser les colonnes numériques
# library("dplyr")
# Rénommons PAY_0 en PAY_1,comme ça on ne quitte plus de PAY_0 subitement à PAY_2
df[1,][df[1,]=='PAY_0'] = 'PAY_1'
#enlevons la ligne 1 qui contient la description de chaque colonne
df = df[-1,-1]
#tranformations les colonones qualitatives en facteur
df$X2 = as.factor(df$X2)#sexe
df$X3 = as.factor(df$X3)#education
df$X4 = as.factor(df$X4)#mariage
df$X6 = as.factor(df$X6)
df$X7 = as.factor(df$X7)
df$X8 = as.factor(df$X8)
df$X9 = as.factor(df$X9)
df$X10 = as.factor(df$X10)
df$X11 = as.factor(df$X11)
df$Y = as.factor(df$Y)#class
# Fin tranformations des colonones qualitatives en facteur
#transformons les colonnes montant en nombre
df$X1 = as.numeric(as.character(df$X1))#limitBalance
df$X5 = as.numeric(as.character(df$X5))#age
cols_to_numeric = 12:23
df[ ,cols_to_numeric] <- apply(df[ , cols_to_numeric], 2,
function(x) as.numeric(as.character(x)))
# Fin transformation les colonnes montant en nombre
#Normalisation des colonnes montant X12-X23 ET X1
df = df %>% mutate(across(where(is.numeric), scale)) #z-score
# df$X1 = (df$X1 - min(df$X1)) / (max(df$X1) - min(df$X1))
# df$X5 = (df$X5 - min(df$X5)) / (max(df$X5) - min(df$X5))
# df[ ,cols_to_numeric] = apply(df[ , cols_to_numeric], 2,
#                     function(x)min_max_norm(x))
# Fin Normalisation des colonnes montant X12-X23 ET X1
return (df)
}
source(main.r)
source("main.r")
source("utils.r")
source("main.r")
main()
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv('dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = '~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining/dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#chargons le repertoire de travail
setwd("~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining")
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = '~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining/dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#chargons le repertoire de travail
setwd("~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining")
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
main <- function() {
#stockons le dataset dans la variable df
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#D'après la commande suivante il n'y a pas de valeurs manquantes
#print(paste('Number of missing values =',sum(is.na(df))))
#pretaitemente
df = pretraitement(df)
#summary(df)
df
}
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv('dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#chargons le repertoire de travail
setwd("~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining/DataMining_project-ram")
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
source("utils.r")
source("main.r")
main()
#summary(df)
return(df)
#summary(df)
df
#pretaitemente
df = pretraitement(df)
#summary(df)
df
#summary(df)
head(df)
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#chargons le repertoire de travail
setwd("~/Documents/Data_science/Data_Mining/Exercices_et_TPs/TP_final_datamining/DataMining_project-ram")
# df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
df = read.csv(file = 'dataset_credit_card.csv',sep=',',header = T,na.strings = '?')
#pretaitemente
df = pretraitement(df)
#summary(df)
head(df)
